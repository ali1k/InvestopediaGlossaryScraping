{"name": "Residual Sum of Squares (RSS) Definition", "@id": "https://www.investopedia.com/terms/r/residual-sum-of-squares.asp", "related": ["https://www.investopedia.com/terms/l/least-squares-method.asp", "https://www.investopedia.com/terms/m/mlr.asp", "https://www.investopedia.com/terms/r/r-squared.asp", "https://www.investopedia.com/terms/s/sum-of-squares.asp", "https://www.investopedia.com/terms/r/residual-standard-deviation.asp", "https://www.investopedia.com/terms/e/errorterm.asp"], "body": ["\nA residual sum of squares (RSS) is a statistical technique used to measure the amount of <a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/v/variance.asp\">variance</a> in a data set that is not explained by a regression model itself. Instead, it estimates the variance in the residuals, or <a data-component=\"link\" data-ordinal=\"2\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/e/errorterm.asp\">error term</a>.\n", "\n<a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/r/regression.asp\" rel=\"noopener noreferrer\">Linear regression</a> is a measurement that helps determine the strength of the relationship between a dependent variable and one or more other factors, known as independent or explanatory variables.\n", "\nwhere:\n", "\nIn general terms, the <a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/s/sum-of-squares.asp\">sum of squares</a> is a statistical technique used in regression analysis to determine the dispersion of data points. In a\u00a0<a data-component=\"link\" data-ordinal=\"2\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/r/regression.asp\">regression analysis</a>, the goal is to determine how well a data series can be fitted to a function that might help to explain how the data series was generated. The sum of squares is used as a mathematical way to find the function that\u00a0<a data-component=\"link\" data-ordinal=\"3\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/l/line-of-best-fit.asp\">best fits</a>\u00a0(varies least) from the data.\n", "\nThe RSS measures the amount of error remaining between the regression function and the data set after the model has been run. A smaller residual sum of squares figure represents a regression function.\n", "\nThe RSS\u2013also known as the sum of squared residuals\u2013essentially determines how well a regression model explains or represents the data in the model.\n", "\n<a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/r/residual-standard-deviation.asp\" rel=\"noopener noreferrer\">Residual standard error</a> *RSE) is another statistical term used to describe the difference in\u00a0<a data-component=\"link\" data-ordinal=\"2\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/s/standarddeviation.asp\" rel=\"noopener noreferrer\">standard deviations</a>\u00a0of observed values versus predicted values as shown by points in a\u00a0<a data-component=\"link\" data-ordinal=\"3\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/articles/financial-theory/09/regression-analysis-basics-business.asp\" rel=\"noopener noreferrer\">regression analysis</a>. It is a\u00a0<a data-component=\"link\" data-ordinal=\"4\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/g/goodness-of-fit.asp\" rel=\"noopener noreferrer\">goodness-of-fit</a>\u00a0measure that can be used to analyze how well a set of data points fit with the actual model.\n", "\nRSE is computed by dividing the RSS by the number of observations in the sample less 2 and then taking the square root: RSE = [RSS/(n-2)]<sup>1/2</sup>\n", "\n<a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/articles/investing/052313/financial-markets-capital-vs-money-markets.asp\" rel=\"noopener noreferrer\">Financial markets</a> have increasingly become more quantitatively driven; as such, in search of an edge, many investors are using advanced statistical techniques to aid in their decisions. Big data, machine learning, and artificial intelligence applications further necessitate the use of statistical properties to guide contemporary investment strategies. The residual sum of squares\u2013or RSS statistics\u2013is one of many statistical properties enjoying a renaissance.\n", "\nStatistical models are used by investors and portfolio managers to track an investment's price and use that data to predict future movements. The study\u2013called regression analysis\u2013might involve analyzing the relationship in price movements between a commodity and the stocks of companies engaged in producing the commodity.\n", "\nAny model might have variances between the predicted values and actual results. Although the variances might be explained by the regression analysis, the residual sum of squares represents the variances or errors that are not explained.\n", "\nSince a sufficiently complex regression function can be made to closely fit virtually any data set, further study is necessary to determine whether the regression function is, in fact, useful in explaining the variance of the dataset. Typically, however, a smaller or lower value for the residual sum of squares is ideal in any model since it means there's less variation in the data set. In other words, the lower the sum of squared residuals, the better the regression model is at explaining the data.\n"]}