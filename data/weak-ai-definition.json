{"name": "Weak AI Definition", "@id": "https://www.investopedia.com/terms/w/weak-ai.asp", "related": ["https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp", "https://www.investopedia.com/terms/s/strong-ai.asp", "https://www.investopedia.com/terms/a/ai-winter.asp", "https://www.investopedia.com/terms/k/knowledge-engineering.asp", "https://www.investopedia.com/terms/s/swot.asp", "https://www.investopedia.com/terms/b/basic-income.asp"], "body": ["\nWeak artificial intelligence (AI)\u2014also called narrow AI\u2014is a type of <a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp\" rel=\"noopener noreferrer\">artificial intelligence</a> that is limited to a specific or narrow area. Weak AI simulates human cognition. It has the potential to benefit society by automating time-consuming tasks and by analyzing data in ways that humans sometimes can\u2019t. Weak AI can be contrasted to <a data-component=\"link\" data-ordinal=\"2\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/s/strong-ai.asp\" rel=\"noopener noreferrer\">strong AI</a>, a theoretical form of machine intelligence that is equal to human intelligence.\n", "\nWeak AI lacks human consciousness, although it may be able to simulate it at times. The classic illustration of weak AI is John Searle\u2019s Chinese room thought experiment. This experiment says that a person outside a room may be able to have what appears to be a conversation in Chinese with a person inside a room who is being given instructions on how to respond to conversations in Chinese. In this experiment, the person inside the room would appear to speak Chinese. In reality, they couldn\u2019t actually speak or understand a word of Chinese absent the instructions they\u2019re being fed. That's because the\u00a0person is good at following instructions, not at speaking Chinese. They might appear to have strong AI\u2014machine intelligence equivalent to human intelligence\u2014but they really only have weak AI.\n", "\nNarrow or weak AI systems do not have general intelligence; they have specific intelligence. An AI that is an expert at telling you how to drive from point A to point B is usually incapable of challenging you to a game of chess. In the same way, a form of AI that can pretend to speak Chinese with you probably cannot sweep your floors.\n", "\nWeak AI helps turn <a data-component=\"link\" data-ordinal=\"1\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/b/big-data.asp\" rel=\"noopener noreferrer\">big data</a> into usable information by detecting patterns and making predictions. Examples of weak AI include Facebook\u2019s newsfeed, Amazon\u2019s suggested purchases\u00a0and Apple\u2019s Siri, the iPhone technology that <a data-component=\"link\" data-ordinal=\"2\" data-source=\"inlineLink\" data-type=\"internalLink\" href=\"https://www.investopedia.com/terms/c/chatbot.asp\" rel=\"noopener noreferrer\">answers users\u2019 spoken questions</a>. Email spam filters are another example of weak AI; a computer uses an algorithm to learn which messages are likely to be spam, then redirects them from the inbox to the spam folder.\n", "\nBesides its limited capabilities, some of the problems with weak AI include the possibility to cause harm if a system fails\u00ad. For example, consider a driverless car that miscalculates the location of an oncoming vehicle and causes a deadly collision. The system also has the possibility to cause harm if the system is used by someone who wishes to cause harm; consider a terrorist who uses a self-driving car to deploy explosives in a crowded area.\n", "\nA further concern related to weak AI is the loss of jobs caused by the automation of an increasing number of tasks. Will unemployment skyrocket, or will society come up with new ways for humans to be economically productive? Although the prospect of a large percentage of workers losing their jobs may be terrifying, advocates of AI claim that it is also reasonable to expect that should this happen, new jobs will emerge that we can\u2019t yet predict as the use of AI becomes increasingly widespread.\n"]}