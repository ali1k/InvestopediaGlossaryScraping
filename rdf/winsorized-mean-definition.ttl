# Winsorized Mean Definition
@prefix invp: <https://www.investopedia.com/vocab/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix schema: <https://schema.org/> .

<https://www.investopedia.com/terms/w/winsorized_mean.asp> a invp:Term ;
    rdfs:label "Winsorized Mean Definition" ;
    schema:url <https://www.investopedia.com/terms/w/winsorized_mean.asp> ;
    invp:description """
Winsorized mean is a method of averaging that initially replaces the smallest and largest values with the observations closest to them. This is done to limit the effect of outliers or abnormal extreme values, or outliers, on the calculation. After replacing the values, the <a data-component="link" data-ordinal="1" data-source="inlineLink" data-type="internalLink" href="https://www.investopedia.com/terms/a/arithmeticmean.asp">arithmetic mean</a> formula is then used to calculate the winsorized mean.

<span data-value="\\begin{aligned} &amp;\\text{Winsorized Mean}\\ =\\ \\frac{x_{n}\\dots x_{n+1}\\ +\\ x_{n+2}\\dots x_{n}}{N}\\\\ &amp;\\textbf{where:}\\\\ &amp;\\begin{aligned} n\\ =\\ &amp;\\text{The number of largest and smallest data}\\\\ &amp;\\text{points to be replaced by the observation}\\\\ &amp;\\text{closest to them}\\end{aligned}\\\\ &amp;N\\ =\\ \\text{Total number of data points} \\end{aligned}">﻿<span class="katex"><span class="katex-mathml">
<math>
<semantics>
<mrow>
<mtable>
<mtr>
<mtd>
<mstyle>
<mrow></mrow>
</mstyle>
</mtd>
<mtd>
<mstyle>
<mrow>
<mrow></mrow>
<mtext>
Winsorized Mean
</mtext>
<mtext>
 
</mtext>
<mo>
=
</mo>
<mtext>
 
</mtext>
<mfrac>
<mrow>
<msub>
<mi>
x
</mi>
<mi>
n
</mi>
</msub>
<mo>
…
</mo>
<msub>
<mi>
x
</mi>
<mrow>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
1
</mn>
</mrow>
</msub>
<mtext>
 
</mtext>
<mo>
+
</mo>
<mtext>
 
</mtext>
<msub>
<mi>
x
</mi>
<mrow>
<mi>
n
</mi>
<mo>
+
</mo>
<mn>
2
</mn>
</mrow>
</msub>
<mo>
…
</mo>
<msub>
<mi>
x
</mi>
<mi>
n
</mi>
</msub>
</mrow>
<mrow>
<mi>
N
</mi>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mstyle>
<mrow></mrow>
</mstyle>
</mtd>
<mtd>
<mstyle>
<mrow>
<mrow></mrow>
<mtext>
where:
</mtext>
</mrow>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mstyle>
<mrow></mrow>
</mstyle>
</mtd>
<mtd>
<mstyle>
<mrow>
<mrow></mrow>
<mtable>
<mtr>
<mtd>
<mstyle>
<mrow>
<mi>
n
</mi>
<mtext>
 
</mtext>
<mo>
=
</mo>
<mtext>
 
</mtext>
</mrow>
</mstyle>
</mtd>
<mtd>
<mstyle>
<mrow>
<mrow></mrow>
<mtext>
The number of largest and smallest data
</mtext>
</mrow>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mstyle>
<mrow></mrow>
</mstyle>
</mtd>
<mtd>
<mstyle>
<mrow>
<mrow></mrow>
<mtext>
points to be replaced by the observation
</mtext>
</mrow>
</mstyle>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mtd>
</mtr>
</mtable>
</mrow>
<annotation encoding="application/x-tex">
\\begin{aligned} &amp;\\text{Winsorized Mean}\\ =\\ \\frac{x_{n}\\dots x_{n+1}\\ +\\ x_{n+2}\\dots x_{n}}{N}\\\\ &amp;\\textbf{where:}\\\\ &amp;\\begin{aligned} n\\ =\\ &amp;\\text{The number of largest and smallest data}\\\\ &amp;\\text{points to be replaced by the observation}\\\\ &amp;\\text{closest to them}\\end{aligned}\\\\ &amp;N\\ =\\ \\text{Total number of data points} \\end{aligned}
</annotation>
</semantics>
</math></span><span class="katex-html"><span class="strut"></span><span class="strut bottom"></span><span class="base"><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="mord"></span></span><span class=""><span class="pstrut"></span><span class="mord"></span></span><span class=""><span class="pstrut"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord mathrm">Winsorized Mean</span></span><span class="mrel"><span class="mspace"> </span><span class="mrel">=</span></span><span class="mord"><span class="mspace"> </span><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="mord"><span class="mord mathit">N</span></span></span><span class=""><span class="pstrut"></span><span class="frac-line"></span></span><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span><span class="minner">…</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">+</span><span class="mord mathrm mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span><span class="mbin"><span class="mspace"> </span><span class="mbin">+</span></span><span class="mord"><span class="mspace"> </span><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">+</span><span class="mord mathrm mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span><span class="minner">…</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord mathbf">where:</span></span></span></span><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="mord"><span class="mord mathit">n</span><span class="mrel"><span class="mspace"> </span><span class="mrel">=</span></span><span class="mspace"> </span></span></span><span class=""><span class="pstrut"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord mathrm">The number of largest and smallest data</span></span></span></span><span class=""><span class="pstrut"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord mathrm">points to be replaced by the observation</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist"></span></span></span></span></span></span></span></span></span></span>﻿

Winsorized means are expressed in two ways. A "k<sup>n</sup>" winsorized mean refers to the replacement of the 'k' smallest and largest observations, where 'k' is an integer. An "X%" winsorized mean involves replacing a given percentage of values from both ends of the data.

The winsorized mean is achieved by replacing the smallest and largest data points, then summing all the data points and dividing the sum by the total number of data points.

The winsorized mean is less sensitive to outliers because it can replace them with less extreme values. That is, it is less susceptible to outliers versus the arithmetic average. However, if a distribution has fat tails, the effect of removing the highest and lowest values in the distribution will have little influence because of the high degree of variability in the <a data-component="link" data-ordinal="1" data-source="inlineLink" data-type="internalLink" href="https://www.investopedia.com/terms/d/distribution.asp">distribution</a> figures.

Let's calculate the winsorized mean for the following data set: 1, 5, 7, 8, 9, 10, 34. In this example, we assume the winsorized mean is in the first order, in which we replace the smallest and largest values with their nearest observations.

The data set now appears as follows: 5, 5, 7, 8, 9, 10, 10. Taking an arithmetic average of the new set produces a winsorized mean of 7.7, or (5 + 5 + 7 + 8 + 9 + 10 + 10) divided by 7. Note that the arithmetic mean would have higher - 10.6. The winsorized mean effectively reduces the influence of the 34 value as an outlier.

Or consider a 20% winsorized mean that takes the top 10% and bottom 10% and replaces them with their next closest value. We will winsorize the following data set: 2, 4, 7, 8, 11, 14, 18, 23, 23, 27, 35, 40, 49, 50, 55, 60, 61, 61, 62, 75. The two smallest and largest data points—10% of the 20 data points—will be replaced with their next closest value. Thus, the new data set is as follows: 7, 7, 7, 8, 11, 14, 18, 23, 23, 27, 35, 40, 49, 50, 55, 60, 61, 61, 61, 61. The winsorized mean is 33.9, or the total of the data (678) divided by the total number of data points (20).

The winsorized mean includes modifying data points, while the <a data-component="link" data-ordinal="1" data-source="inlineLink" data-type="internalLink" href="https://www.investopedia.com/terms/t/trimmed_mean.asp">trimmed mean</a> involves removing data points. It is common for the winsorized mean and trimmed mean to be close or sometimes equal in value to one another.

One major downside for winsorized means is that they naturally introduce some bias into the data set. By reducing the influence of outliers, the analysis is modified for better analysis, but also removes information about the underlying data.
""" ;
    invp:relates_to <https://www.investopedia.com/terms/a/arithmeticmean.asp>,
        <https://www.investopedia.com/terms/c/correlation.asp>,
        <https://www.investopedia.com/terms/d/decile.asp>,
        <https://www.investopedia.com/terms/i/inverse-correlation.asp>,
        <https://www.investopedia.com/terms/s/standarddeviation.asp>,
        <https://www.investopedia.com/terms/t/trimmed_mean.asp> .

